{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pruebo varios modelos usando TF IDF.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_VAbSm9Y2B3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 877
        },
        "outputId": "5fb920ec-4183-4971-96ec-59a7f1d1b794"
      },
      "source": [
        "!pip install textacy\n",
        "!pip install catboost\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "import string\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords\n",
        "import textacy\n",
        "from textblob import TextBlob\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from wordcloud import WordCloud"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: textacy in /usr/local/lib/python3.6/dist-packages (0.10.0)\n",
            "Requirement already satisfied: cachetools>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from textacy) (4.1.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from textacy) (1.4.1)\n",
            "Requirement already satisfied: pyemd>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from textacy) (0.5.1)\n",
            "Requirement already satisfied: srsly>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from textacy) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.6/dist-packages (from textacy) (1.18.5)\n",
            "Requirement already satisfied: jellyfish>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from textacy) (0.8.2)\n",
            "Requirement already satisfied: pyphen>=0.9.4 in /usr/local/lib/python3.6/dist-packages (from textacy) (0.9.5)\n",
            "Requirement already satisfied: spacy>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from textacy) (2.2.4)\n",
            "Requirement already satisfied: cytoolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from textacy) (0.10.1)\n",
            "Requirement already satisfied: joblib>=0.13.0 in /usr/local/lib/python3.6/dist-packages (from textacy) (0.16.0)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from textacy) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.19.6 in /usr/local/lib/python3.6/dist-packages (from textacy) (4.41.1)\n",
            "Requirement already satisfied: scikit-learn>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from textacy) (0.22.2.post1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from textacy) (2.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->textacy) (7.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->textacy) (3.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->textacy) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->textacy) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->textacy) (2.0.3)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->textacy) (1.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->textacy) (49.2.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->textacy) (0.7.1)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->textacy) (0.4.1)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz>=0.8.0->textacy) (0.10.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->textacy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->textacy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->textacy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->textacy) (2020.6.20)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->textacy) (4.4.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.0->textacy) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.0->textacy) (3.1.0)\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.6/dist-packages (0.24)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.0.5)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.2.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbvkkZgGY8Qg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_original = pd.read_csv('https://raw.githubusercontent.com/maxrinal/nlp-disaster/master/train.csv')\n",
        "test_original = pd.read_csv('https://raw.githubusercontent.com/maxrinal/nlp-disaster/master/test.csv')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvjZh0f5ZB7g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train=train_original.drop(columns=['keyword', 'location'])\n",
        "test = test_original.drop(columns=['keyword', 'location'])\n",
        "train['text'] = train['text'].str.lower()\n",
        "test['text'] = test['text'].str.lower()\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    return text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "train['text_clean'] = train.text.apply(lambda x: remove_punctuation(x))\n",
        "test['text_clean'] = test.text.apply(lambda x: remove_punctuation(x))\n",
        "\n",
        "STOPWORDS = set(stopwords.words('english') +  ['u', 'Ã¼', 'ur', '4', '2', 'im', 'dont', 'doin', 'ure'])\n",
        "def stopwords_(text):\n",
        "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
        "\n",
        "train['text_clean'] = train['text_clean'].apply(lambda text: stopwords_(text))\n",
        "test['text_clean'] = test['text_clean'].apply(lambda text: stopwords_(text))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ew0bMV4gZKk_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "def lemmatizer_(text):\n",
        "    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
        "\n",
        "train['text_clean'] = train['text_clean'].apply(lambda text: lemmatizer_(text))\n",
        "test['text_clean'] = test['text_clean'].apply(lambda text: lemmatizer_(text))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkQ4d8vFZLLX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.text_clean = train.text_clean.str.translate(str.maketrans('','','1234567890'))\n",
        "test.text_clean = test.text_clean.str.translate(str.maketrans('','','1234567890'))\n",
        "\n",
        "train['text_clean'] = train['text_clean'].apply(lambda x: ' '.join( [ a for a in x.split() if len(a)> 1 ]))\n",
        "test['text_clean'] = test['text_clean'].apply(lambda x: ' '.join( [ a for a in x.split() if len(a)> 1 ]))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLIcdKBTBl0U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "seed = 42\n",
        "\n",
        "X = train.text_clean\n",
        "y = train.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=seed)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgAM-s9OBt1L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression, PassiveAggressiveClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ImiHldjBxPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def acc_summary(pipeline, X_train, y_train, X_test, y_test):\n",
        "    sentiment_fit = pipeline.fit(X_train, y_train)\n",
        "    y_pred = sentiment_fit.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "   \n",
        "    print(\"-\"*30)\n",
        "    \n",
        "    print(\"accuracy score: {0:.2f}%\".format(accuracy*100))\n",
        "    \n",
        "    print(\"-\"*30)\n",
        "    \n",
        "    return accuracy"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atghTRS8B1Gi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\",\"XGBoost\", \"Logistic Regression\",\"Naive Bayes\", \"SVC\"]\n",
        "\n",
        "classifiers = [\n",
        "    KNeighborsClassifier(n_neighbors=3),\n",
        "    DecisionTreeClassifier(random_state=0),\n",
        "    RandomForestClassifier(n_estimators=100),\n",
        "    xgb.XGBClassifier(objective ='binary:logistic', \n",
        "                colsample_bytree = 0.3, learning_rate = 0.1,\n",
        "                max_depth = 20, alpha = 10, n_estimators = 150),\n",
        "    LogisticRegression(),\n",
        "    MultinomialNB(),\n",
        "    SVC(kernel=\"linear\")\n",
        "]\n",
        "    \n",
        "zipped_clf = zip(names, classifiers)\n",
        "tvec = TfidfVectorizer()\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "def compare_clf(classifier=zipped_clf, vectorizer=tvec, n_features=10000, ngram_range=(1, 1)):\n",
        "    result = []\n",
        "    vectorizer.set_params(stop_words=stop_words, max_features=n_features, ngram_range=ngram_range)\n",
        "    for n, c in classifier:\n",
        "        checker_pipeline = Pipeline([\n",
        "            (\"vectorizer\", vectorizer),\n",
        "            (\"classifier\", c)\n",
        "        ])\n",
        "        clf_acc = acc_summary(checker_pipeline, X_train, y_train, X_test, y_test)\n",
        "        print(\"Model result for {}\".format(n))\n",
        "        print(c)\n",
        "        result.append((n, clf_acc))\n",
        "    return result"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yknOCUPRB9Dy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4cd14f5d-0e80-4409-a86e-c515a5a26d24"
      },
      "source": [
        "trigram_result = compare_clf()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------\n",
            "accuracy score: 70.27%\n",
            "------------------------------\n",
            "Model result for K Nearest Neighbors\n",
            "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
            "                     weights='uniform')\n",
            "------------------------------\n",
            "accuracy score: 72.02%\n",
            "------------------------------\n",
            "Model result for Decision Tree\n",
            "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
            "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
            "                       random_state=0, splitter='best')\n",
            "------------------------------\n",
            "accuracy score: 76.84%\n",
            "------------------------------\n",
            "Model result for Random Forest\n",
            "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False)\n",
            "------------------------------\n",
            "accuracy score: 77.63%\n",
            "------------------------------\n",
            "Model result for XGBoost\n",
            "XGBClassifier(alpha=10, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=0.3, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=20,\n",
            "              min_child_weight=1, missing=None, n_estimators=150, n_jobs=1,\n",
            "              nthread=None, objective='binary:logistic', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=1, verbosity=1)\n",
            "------------------------------\n",
            "accuracy score: 81.13%\n",
            "------------------------------\n",
            "Model result for Logistic Regression\n",
            "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "------------------------------\n",
            "accuracy score: 80.43%\n",
            "------------------------------\n",
            "Model result for Naive Bayes\n",
            "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
            "------------------------------\n",
            "accuracy score: 79.68%\n",
            "------------------------------\n",
            "Model result for SVC\n",
            "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNGm8TehCbsR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "9cf2de3a-4188-4668-8bfb-fb58f270b756"
      },
      "source": [
        "trigram_result"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('K Nearest Neighbors', 0.7027145359019265),\n",
              " ('Decision Tree', 0.7202276707530648),\n",
              " ('Random Forest', 0.7683887915936952),\n",
              " ('XGBoost', 0.7762697022767076),\n",
              " ('Logistic Regression', 0.8112959719789843),\n",
              " ('Naive Bayes', 0.8042907180385289),\n",
              " ('SVC', 0.7968476357267951)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrZewAqEChRB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def prediction(pipeline, testtext):\n",
        "    sentiment_fit = pipeline.fit(X_train,y_train)\n",
        "    y_pred = sentiment_fit.predict(testtext)\n",
        "    \n",
        "    return y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yC3iiVgWCj4R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer=TfidfVectorizer()\n",
        "checker_pipeline = Pipeline([\n",
        "            ('vectorizer', vectorizer),\n",
        "            ('classifier', KNeighborsClassifier(n_neighbors=6))\n",
        "        ])\n",
        "vectorizer.set_params(stop_words=None, max_features=100000, ngram_range=(1,4))\n",
        "prediction=prediction(checker_pipeline,test['text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewJs3NheIJB_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction_random_forest = pd.DataFrame({'id':test.id, 'target':prediction} )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyoikyEjF5wN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction_logistic_Regresion =  pd.DataFrame({'id':test.id, 'target':prediction} )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emrv0lA0Ibcw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction_knn = pd.DataFrame({'id':test.id, 'target':prediction} )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJ0PHuQqClUh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = pd.DataFrame({'id':test.id, 'target':prediction} )\n",
        "result.to_csv('prueba_random_forest.csv',header=True,index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ferw8qD1CwBy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "18c7b17c-c6f4-4777-830b-6286d8e9d8a9"
      },
      "source": [
        "from functools import reduce\n",
        "dfs = [prediction_random_forest, prediction_logistic_Regresion, prediction_knn]\n",
        "df_final = reduce(lambda left,right: pd.merge(left,right,on='id'), dfs)\n",
        "df_final['target_final'] =((df_final['target_x'] + df_final['target_y'] + df_final['target']) / 3).round()\n",
        "\n",
        "df_final = df_final[['id', 'target_final']]\n",
        "df_final.columns = ['id', 'target']\n",
        "df_final"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3258</th>\n",
              "      <td>10861</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3259</th>\n",
              "      <td>10865</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3260</th>\n",
              "      <td>10868</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3261</th>\n",
              "      <td>10874</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3262</th>\n",
              "      <td>10875</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3263 rows Ã 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  target\n",
              "0         0     0.0\n",
              "1         2     1.0\n",
              "2         3     1.0\n",
              "3         9     0.0\n",
              "4        11     1.0\n",
              "...     ...     ...\n",
              "3258  10861     1.0\n",
              "3259  10865     0.0\n",
              "3260  10868     1.0\n",
              "3261  10874     1.0\n",
              "3262  10875     1.0\n",
              "\n",
              "[3263 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSlwvVWSK4yR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_final.to_csv('prueba_combino_randomForest_Knn_regresionLogistica.csv',header=True,index = False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}